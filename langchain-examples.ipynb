{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b211ba",
   "metadata": {},
   "source": [
    "# LangChain Hello World - Python Examples\n",
    "\n",
    "This notebook demonstrates various LangChain capabilities in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfda338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic chat example\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that explains concepts simply.\"),\n",
    "    HumanMessage(content=\"What is LangChain and why is it useful?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(\"ü§ñ AI Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27280fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation with memory\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"üí¨ Starting conversation with memory...\")\n",
    "response1 = conversation.predict(input=\"Hi! My name is John and I'm learning about AI.\")\n",
    "print(f\"Response 1: {response1}\")\n",
    "\n",
    "response2 = conversation.predict(input=\"What's my name?\")\n",
    "print(f\"Response 2: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69670049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test different prompts\n",
    "def test_prompt(prompt):\n",
    "    \"\"\"Test a prompt and return the response\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a creative assistant.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "# Test different prompts\n",
    "prompts = [\n",
    "    \"Write a haiku about programming\",\n",
    "    \"Explain quantum computing in 50 words\",\n",
    "    \"What are the benefits of using LangChain?\"\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\nüìù Prompt {i}: {prompt}\")\n",
    "    print(f\"ü§ñ Response: {test_prompt(prompt)}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1b30f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try modifying the prompts and system messages\n",
    "- Experiment with different temperature values\n",
    "- Explore other LangChain components like chains, agents, and tools\n",
    "- Check out the LangChain documentation for more advanced features"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
